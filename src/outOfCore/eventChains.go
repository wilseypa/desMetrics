	// in this next step, we are going to compute event received summaries.  in this case we are going to
	// attack the problem by slicing the lps array and assigning each slice to a separate goroutine.  to
	// optimize performance we are going to have each goroutine perform all analyses and pass the results LP
	// by LP back to the main routine.  in each pass over an LP each goroutine will: (i) compute the
	// local/remote event data, (ii) record the LPs that send events to this LP and compute the coverage
	// statistics, and (iii) the (local, global, and linked) chain info for each LP.  while these
	// computations can technically be folded together and performed in one pass over each LP's event data, we
	// will keep them separate in order to keep the algorithm cleaner.  

	// in this next step, we are going to compute event received summaries.  in this case we are going to
	// compute two different results.  the first is a simple count of the (i) total events received, (ii)
	// the local events received local and, (iii) the remote events received.  in this case local means
	// events sent and received by the same LP, remote means events sent by some other LP.  the second
	// computation is the number of sending LPs to cover a certain percentage of the total events
	// received.  for example, how many LP (say X) were responsible for 75% of the events received by this
	// LP.  for this we will order the sending LP counts so that they are ordered by decreasing number of 
	// events sent to this LP.


	// this helper function will compute the number of LPs (sorted by most sending to least sending) that
	// result in coverage of the percent of events received (basically how many LPs send X% of the
	// received messages).
	numOfLPsToCover := func(total int, data []int, percent int) int {
		// add .99 because int() truncates and we actually want rounding
		numRequired := int(((float32(total) * float32(percent)) / float32(100)) + .99)
		// ok, we had a corner case where this test is needed
		if (numRequired > total) {numRequired = total}
		lpCount := 0
		eventCount := 0
		for i := range data {
			lpCount++
			eventCount = eventCount + data[i]
			if eventCount >= numRequired {
				return lpCount
			}
		}
		fmt.Printf("ERROR: something's amiss in this computation: %v, %v, %v, %v, %v\n", total, percent, numRequired, eventCount, len(data))
		panic("aborting.")
	}

	// data type to capture each LP's event summary data
	type lpEventSummary struct {
		lpId int
		local int
		remote int
		total int
		cover [5]int
		localChain []int
		linkedChain []int
		globalChain []int
	}

	// compute the local/remote events and cover statistics
	computeLPEventsProcessed := func(lp lpData) lpEventSummary {
		var es lpEventSummary
		lpEventSendCount := make([]int,numOfLPs)
		es.lpId = lp.lpId
		es.local = 0
		es.remote = 0
		for _, event := range lp.events {
			if lp.lpId != event.companionLP {
				es.remote++
				// we don't want to count self generated events in the sender set.
				lpEventSendCount[event.companionLP]++
			} else {
				es.local++
			}
		}
		sort.Sort(sort.Reverse(sort.IntSlice(lpEventSendCount)))
		es.total = es.remote + es.local
		// since we're tracking message transmissions, use only the remote event total
		es.cover[0] = numOfLPsToCover(es.remote, lpEventSendCount, 75)  //  75% cutoff
		es.cover[1] = numOfLPsToCover(es.remote, lpEventSendCount, 80)  //  80% cutoff
		es.cover[2] = numOfLPsToCover(es.remote, lpEventSendCount, 90)  //  90% cutoff
		es.cover[3] = numOfLPsToCover(es.remote, lpEventSendCount, 95)  //  95% cutoff
		es.cover[4] = numOfLPsToCover(es.remote, lpEventSendCount, 100) // 100% cutoff
		return es
	}

	// event chains are collections of events for execution at the LP that could potentially be executed
	// together.  thus when examining an event with receive timestamp t, the chain is formed by all future
	// (by receive time) events in that LP that have a send time < t.  local chains have the additional
	// constraint that they must also have been sent by the executing LP (self generated events).  global
	// chains can be sent from any LP.

	// a third form of event chains is the "linked event chain".  the linked chain is similar to the local
	// chain except that the constraint on the send time is relaxed so that any event sent within the time
	// window of the local event chain (so basically any event generated by the chain is also potentially
	// a member of the chain).

	// consider a locally linked chain computation.  that is, anything generated within the time frame of
	// the chain should also be included in the chain length computation

	// all chains longer than this will be summed as if they are this length.
	chainLength := 5

	accumulateChain := func(chain []int, maxChainLength int, chainLength int) {
		if chainLength >= maxChainLength {chain[maxChainLength - 1]++} else {chain[chainLength]++}
		return
	}

	// PAW: consider changing these to being strictly less than the receiveTime
	computeEventChains := func(lp lpData) ([]int, []int, []int) {

		local := make([]int,chainLength)
		linked := make([]int,chainLength)
		global := make([]int,chainLength)

		// LOCAL CHAINS: an event is part of the local chain if it is (i) generated by this LP (lpId) and (ii)
		// if it's send time is less than the receive time of the event at the head of the chain.
		i := 0
		for ; i < len(lp.events) ; {
			// skip over non local events
			for ; i < len(lp.events) && lp.events[i].companionLP != lp.lpId ; i++ {}
			j := i + 1
			// find end of chain
			for ; j < len(lp.events) && lp.events[j].companionLP == lp.lpId && lp.events[j].sendTime < lp.events[i].receiveTime ; {j++}
			accumulateChain(local, chainLength, j-i-1)
			i = j
		}
		
		// LINKED CHAINS: an event is part of the linked chain if it is (i) generated by this LP (lpId) and (ii)
		// if it's send time is less than or equal to the receive time (NOTE the change from local chains) of
		// any event currently in the chain (tested against the last event already in the chain)
		i = 0
		for ; i < len(lp.events) ; {
			// skip over non local events
			for ; i < len(lp.events) && lp.events[i].companionLP != lp.lpId ; i++ {}
			j := i + 1
			// find end of chain
			for ; j < len(lp.events) && lp.events[j].companionLP == lp.lpId && lp.events[j].sendTime <= lp.events[j-1].receiveTime ; {j++}
			accumulateChain(linked, chainLength, j-i-1)
			i = j
		}
		
		// GLOBAL CHAINS: an event is part of the global chain if it is has a send time that is less the receive
		// time of any event currently in the chain (tested against the last event already in the chain)
		i = 0
		for ; i < len(lp.events) ; {
			j := i + 1
			for ; j < len(lp.events) && lp.events[j].sendTime < lp.events[i].receiveTime ; {j++}
			accumulateChain(global, chainLength, j-i-1)
			i = j
		}
		return local, linked, global
	}

	// PAW: change the comment headers of chains/covers to for loops so the numbers will automatically grow
	// with the variable setting.... 
	localChainFile, err := os.Create("analysisData/localEventChainsByLP.csv")
	if err != nil {panic(err)}
	fmt.Fprintf(localChainFile,"# local event chains by LP\n")
	fmt.Fprintf(localChainFile,"# LP, local chains of length: 1, 2, 3, 4, ... , >= n\n")

	linkedChainFile, err := os.Create("analysisData/linkedEventChainsByLP.csv")
	if err != nil {panic(err)}
	fmt.Fprintf(linkedChainFile,"# linked event chains by LP\n")
	fmt.Fprintf(linkedChainFile,"# LP, linked chains of length: 1, 2, 3, 4, ... , >= n\n")

	globalChainFile, err := os.Create("analysisData/globalEventChainsByLP.csv")
	if err != nil {panic(err)}
	fmt.Fprintf(globalChainFile,"# global event chains by LP\n")
	fmt.Fprintf(globalChainFile,"# LP, global chains of length: 1, 2, 3, 4, ... , >= n\n")

	// location to write summaries of local and remote events received
	eventSummaries, err := os.Create("analysisData/eventsExecutedByLP.csv")
	if err != nil {panic(err)}
	fmt.Fprintf(eventSummaries, "# summary of local and remote events executed\n")
	fmt.Fprintf(eventSummaries, "# LP, local, remote, total\n")

	// location to write percentage of LPs to cover percentage of events received
	numToCover, err := os.Create("analysisData/numOfLPsToCoverPercentEventMessagesSent.csv")
	if err != nil {panic(err)}
	fmt.Fprintf(numToCover,"# number of destination LPs (sorted by largest messages sent to) to cover percentage of total events\n")
	fmt.Fprintf(numToCover,"# LP name, total events sent, num of LPs to cover: 75, 80, 90, 95, and 100 percent of the total events sent.\n")

	// this will be invoked as a gogroutine with LPs equally (nearly) partitioned among them
	analyzeReceivedEvents := func (lps []lpData, c chan<- lpEventSummary) {
		for _, lp := range(lps) {
			eventsProcessed := computeLPEventsProcessed(lp)
			eventsProcessed.localChain, eventsProcessed.linkedChain, eventsProcessed.globalChain = computeEventChains (lp)
			c <- eventsProcessed
		}
	}

	// defining how many LPs do we assign to each thread
	goroutineSliceSize := int((float32(len(lps))/float32(numThreads)) + .5)

	// each goroutine will compute event counts for one LP, send the results back over the channel and
	// continue. 
	c := make(chan lpEventSummary, numThreads * 4)
	for i := 0; i < numThreads; i++ {
		low := i * goroutineSliceSize
		high := low + goroutineSliceSize
		if i == numThreads - 1 {high = len(lps)}
		go analyzeReceivedEvents(lps[low:high], c)
	}

	localEventChainSummary := make([]int,chainLength)
	linkedEventChainSummary := make([]int,chainLength)
	globalEventChainSummary := make([]int,chainLength)

	// process all of the data in the channel and output the results
	for _ = range lps {
		eventsProcessed := <- c
		// capture event chain summaries
		for i := 0; i < chainLength; i++ {
			localEventChainSummary[i] = localEventChainSummary[i] + eventsProcessed.localChain[i]
			linkedEventChainSummary[i] = linkedEventChainSummary[i] + eventsProcessed.linkedChain[i]
			globalEventChainSummary[i] = globalEventChainSummary[i] + eventsProcessed.globalChain[i]
		}
		fmt.Fprintf(eventSummaries,"%v, %v, %v, %v\n", 
			mapIntToLPName[eventsProcessed.lpId], eventsProcessed.local, eventsProcessed.remote, eventsProcessed.local + eventsProcessed.remote)
		// PAW: turn this into a for loop so the variable will actually control
		fmt.Fprintf(numToCover,"%v, %v", mapIntToLPName[eventsProcessed.lpId], eventsProcessed.remote)
		for _, i := range eventsProcessed.cover {fmt.Fprintf(numToCover,", %v", i)}
		fmt.Fprintf(numToCover,"\n")
		fmt.Fprintf(localChainFile,"%v",mapIntToLPName[eventsProcessed.lpId])
		fmt.Fprintf(linkedChainFile,"%v",mapIntToLPName[eventsProcessed.lpId])
		fmt.Fprintf(globalChainFile,"%v",mapIntToLPName[eventsProcessed.lpId])
		for i := range eventsProcessed.localChain {
			fmt.Fprintf(localChainFile,", %v", eventsProcessed.localChain[i])
			fmt.Fprintf(linkedChainFile,", %v", eventsProcessed.linkedChain[i])
			fmt.Fprintf(globalChainFile,", %v", eventsProcessed.globalChain[i])
		}
        fmt.Fprintf(localChainFile,"\n")
        fmt.Fprintf(linkedChainFile,"\n")
        fmt.Fprintf(globalChainFile,"\n")
	}
	close(c)

	err = eventSummaries.Close()
	if err != nil {panic(err)}
	err = numToCover.Close()
	if err != nil {panic(err)}
	err = localChainFile.Close()
	if err != nil {panic(err)}
	err = linkedChainFile.Close()
	if err != nil {panic(err)}
	err = globalChainFile.Close()
	if err != nil {panic(err)}

	// number of LPs with n event chains of length X number of LPs with average event chains of length X
	
	// not sure this will be useful or not, but let's save totals of the local and global event chains.
	// specifically we will sum the local/global event chains for all of the LPs in the system

	outFile, err = os.Create("analysisData/eventChainsSummary.csv")
	if err != nil {panic(err)}
	fmt.Fprintf(outFile,"# number of event chains of length X\n")
	fmt.Fprintf(outFile,"# chain length, num of local chains, num of linked chains, num of global chains\n")
	for i := 0; i < chainLength; i++ {
		fmt.Fprintf(outFile,"%v, %v, %v, %v\n", i+1,
			localEventChainSummary[i],linkedEventChainSummary[i],globalEventChainSummary[i])
	}
	err = outFile.Close()
	if err != nil {panic(err)}
